{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage of trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload after code has changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first time, moving up one dir level\n",
      "This path should be the root directory of the project:  /home/daniel/Documents/TUM/ADLR/tum-adlr-02\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# move into the correct dirrectory, e.g. move up one directory level iif this cell is run for the first time\n",
    "try:\n",
    "    a = first_time\n",
    "except NameError:\n",
    "    print(\"Running first time, moving up one dir level\")\n",
    "    os.chdir('..')  # Move up one directory level to the root directory of project\n",
    "    first_time = False\n",
    "\n",
    "print(\"This path should be the root directory of the project: \", os.getcwd())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset\n",
    "Creating the dataset object and applzing transformations to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.model_classes import Mug, Bottle\n",
    "from data.dataconverter import DataConverter\n",
    "\n",
    "# generate data\n",
    "dataconverter = DataConverter(\n",
    "    classes=[Mug(),Bottle()],\n",
    "    min_order = 1,\n",
    "    tact_order = 10,\n",
    "    tact_number=2, \n",
    "    rand_rotations=2\n",
    "    \n",
    ")\n",
    "# set regenerate to true, if you run this after changes in dataconverter have been made\n",
    "#dataconverter.generate_2d_dataset(show_results=False, regenerate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.reconstruction_dataset import *\n",
    "\n",
    "csv_file = './datasets/2D_shapes/annotations.csv'\n",
    "root_dir = './datasets/2D_shapes'\n",
    "composed = transforms.Compose([RandomOrientation(),\n",
    "                               ToTensor()])\n",
    "\n",
    "dataset = ReconstructionDataset(csv_file=csv_file,\n",
    "                                root_dir=root_dir,\n",
    "                                transform=composed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examplary data pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAEMCAYAAABZZbUfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAKR0lEQVR4nO3daYxddR3H4d+dmXbaaYFAV4rUgnRYDBWIlHYIShQIClEJQoCY1AAmVYhWZUk0YsISYzSCLBWoAWyiEMEl8YUiJmq0lGjBVg1IlVLbAk0LAqXbdJbrC6MG2tBZ7u1/zv09TzJvTs6c+SaTzHxy5p47tXq9Xg8AIK220gMAgLLEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5DqGeuLZbRc1cwcA0ASPDT6833PcGQCA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJLrKD0AgOa44Omt0dP13F7H++pt8aWj5hdYxFglBgBaQP+vZsf93T9407Ej2ruivTZhn+fftv7xWDKn50BMowLEAEALmDJhR8zumDzk89/Z4cc//+c1A4l0HD4zap2dpWcAMMaIgUQ2LD0s+nveXXoGAGOM+0SJzLrg6dITgCYZrNdKT6DC3BkAaAFvnPFyXP3CacP7pJqA4D/EAEBCXW3j46ENK0rPYIwQAwCQnBgAgOTEAAAkJwYAIDkxANAinnl9Ruwc3FN6BhUkBgBaRMdZG+Jb/5o35PPbarVoP35uExdRFWIAIKlD2ibGXb+4v/QMxgAxkNBz31wQHXNml54BwBghBhKa9mRE/Y3tpWcAMEaIgYQ2n9UfceghpWcAMEaIgYTm/DAitrxSegbQBPc9dXps6nfnj+ERAwmNf3RVDGzbVnoG0ARzP/lkPLrjmCGff1BbLV5dtLCJi6gCMQCQ2NT2SfHITd+IzZ/riVeuEAVZdZQeAEBZszsmx5rrl8bq3t64fPySmPadlaUncYCJAYAWsfXTC2PHrIgTJ9weEeOG/fkndXbGHdfeFZfPuiomvRAx7W5RkEWtXq/Xh3Li2W0XNXsLACO05eqeuHnJfXFe1+6GXO9TG0+PDaftaMi1KOuxwYf3e47XDAC0gLmXPNuwEIiIuHDKqnjpiz0Nux5jmxgAqLgXr+uJRTNXNPSa53b1xs2LHxAESYgBgIqbfs6mht4V+K+PTNoZNy5eHi9eKwhanRgAqLCNX+6J6+f8vGnX/9ik7RE9rzXt+owNYgCgwsad+mqc09VXegYVJwYAeFt3zHsoNn7FnwpamRgAqKj1tyyMZe9Z3vSvc+bEweg9dlfTvw7liAGAiho8alfM7xz+mwuNxIOn3xsbbnB3oFWJAQD2a37nuNg9q7/0DJpEDABAcmIAAJITAwCQnBgAgOTEAABD8pfzb4/nv7aw9AyaQAwAMCST2ybEYEfpFTSDGABg6Gr10gtoAjEAAMmJgQR2nz8/2rvfVXoG0GBHX7Y6Tv7jJaVn0ALEQAKvze2IvukHlZ4BNMFgvVZ6Ai1ADCQw89bHo+33q0vPAFrAPy67O/55oycKWo0YAIDkxAAAJCcGACps167xsX1wd+kZVJwYAKiwoy5dEx/928WlZ1BxYgAAkhMDAAzLnimD0T51SukZNJAYAGBY1l1wT2y44tjSM2ggMUBTrL9pYbxypWeRAarA/5+iKY65d2PUd/fGQOkhAOyXOwM0Rf/GTTGwdWvpGZDC+r/Oij/v8XghIycGACrumCVPxM2bzis9gwoTAzTF3+84LTZ/vqf0DKBJ9py8PdpP6C49gwYRAzRF9zWr4/A7V5WeATTJ2vctj5c+MLX0DBrECwhpinpvb+kJAAyROwMAkJwYAIDkxABAC1j3ve740faDS8+gosQAQAuYsmxl/Pr140vPoKLEAAAjsnDRUzFw5imlZ9AAYgCAEVl6xBOx7Z2dpWfQAGIAAJITAzRV+4zp0dbVVXoGAG9DDNBUz9wyO9748ImlZ0AKaz97XDywbXrpGVSQdyCkqbqv9JbEcKDUVq6JTXsOi4gtpadQMe4MAEByYgCAEbv9q3fG7vPnl57BKIkBAEZswYT26J9YKz2DURIDAJCcGACA5MQAQAtZseCwWL5taukZVIwYAGghgzt3Rl/dU+MMjxgAYFR+c9vS6P3QqaVnMApiAIBRGVdrj/BAQaWJAQBITgwAtJi+envpCVSMGABoMT85YVr8dMfk0jOoEDEAAMmJAQBGrW9SW0SbP09UlRgAYNRWfPueGDxjXukZjJAYAIDkxAAAJCcGAFrQI1vfG731vtIzqAgxANCCtva8Fqt6vaCPoREDADTElpMmRtukSaVnMAJiAICGWHP90qgfN6f0DEZADABAcmIAAJITAwCQnBgAaFGf+OXieH1wV+kZVIAYAGhR3Yv/EJv6S6+gCsQAAA3z7FUTo33atNIzGCYxAEDDPH/udyOmHVp6BsMkBgAgOTEAAMmJAYAWtuiWL3iigP0SAwAtbMqylbFzcKD0DMY4MQAAyYkBABrqxO+vjY6ZM0rPYBjEAAAN9fUZqyMmdJaewTCIAQBITgwAQHJiAKDFXXHWIo8X8rbEAECLG1j7XOkJjHFiAICGu/W3D/qHRRUiBgBouO5xk6LW7ldMVfhOAUByYgAAkhMDAJCcGABI4OJ3LIzeel/pGYxRYgCA5qjVSi9giMQAAA3RW+9708ePV/0s2g8+uPQshqCj9AAAqqW33he76/17Hf/4pZ+Jtt/96S1Htx2YUYyKGABgL331gXh5YN9vYfzBZdfFkTc9vtfxtnhrCFAVYgAgiWf7BmLe+HF7HV/bt2OvY9esvzB63795n9c5MvYOAapNDAAkce2cBXHDuqdiXG3gf8fW7Zke9x970j7O3ncI0JrEAEAiNx59SukJjEGeJgCA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQnBgAgOTEAAAkJwYAIDkxAADJiQEASE4MAEByYgAAkhMDAJCcGACA5MQAACQnBgAgOTEAAMmJAQBITgwAQHJiAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJITAwCQXK1er9dLjwAAynFnAACSEwMAkJwYAIDkxAAAJCcGACA5MQAAyYkBAEhODABAcmIAAJL7N2/ddQaJsDwjAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_data = dataset[5]\n",
    "\n",
    "plt.figure()\n",
    "print(example_data['image'])\n",
    "show_datapair(example_data['image'], example_data['label'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Hyperparamters\n",
    "\n",
    "Look into the file neural_nets.trainer to see which hyperparameters you can choose.\n",
    "The seperation into tunable and non tunable hyperparameters is made, because this makes parameter searches with ray easier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non Tunable Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_nets.trainer import NonTHparams\n",
    "\n",
    "\n",
    "nt_h = NonTHparams()\n",
    "nt_h.num_epochs = 50\n",
    "nt_h.train_prop = 0.93 # set way to high to make validation period short and make testing this search easier\n",
    "\n",
    "nt_h.print_log = True # to better see param search results\n",
    "nt_h.log_train_period = 100\n",
    "nt_h.log_val_freq = 5 #int(nt_h.train_prop*len(dataset)/f)-1 #set low to test this parameter search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Tunable Hyperparameters and parameter spaces for upgrade\n",
    "\n",
    "The hyperparameters we want to tone have to be put into a list of possible values and that list into a dict, for the hyperparameter optimizer to do its job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from neural_nets.trainer import THparams\n",
    "from neural_nets.weight_inits import weight_init_kx\n",
    "from neural_nets.models.unet import UNet2\n",
    "\n",
    "\n",
    "from ray import tune\n",
    "from ray import train\n",
    "from ray.train import Checkpoint, get_checkpoint\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import ray.cloudpickle as pickle\n",
    "\n",
    "t_h = THparams()\n",
    "t_h.batch_size = 16\n",
    "\n",
    "t_h.model = UNet2\n",
    "t_h.weight_init = weight_init_kx\n",
    "t_h.depth = 5\n",
    "t_h.channels = 64\n",
    "\n",
    "t_h.lr = 1e-4\n",
    "t_h.optimizer = optim.Adam\n",
    "t_h.loss_func = nn.BCELoss()\n",
    "\n",
    "\n",
    "image_resolution = dataset[0]['image'].shape[1]\n",
    "max_unet_depth = int(np.log2(image_resolution))\n",
    "\n",
    "# config is the set of params, that will be searched, they got to ghave the same key names, as variables in THparams\n",
    "config = {\n",
    "    \"batch_size\": tune.choice([2 ** i for i in range(2,5)]),\n",
    "    \"lr\": tune.loguniform(1e-7, 1e-2),\n",
    "    \"depth\": tune.choice([i for i in range(3,max_unet_depth+1-2)]),\n",
    "    \"channels\": tune.choice([2 ** i for i in range(4,9)])\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During training, progress will be logged to tensorboard. Go to project folder, activate appropritae conda environment and run 'tensorboard --logdir runs/' to see the logs.\n"
     ]
    }
   ],
   "source": [
    "from neural_nets.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(nt_h, t_h, dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 15:42:47,188\tINFO worker.py:1761 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray dashboard URL:  127.0.0.1:8265\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import GPUtil\n",
    "\n",
    "\n",
    "\n",
    "os.environ[\"RAY_CHDIR_TO_TRIAL_DIR\"] = \"0\" # needed so that we still can load files using path relative to working directory, \n",
    "                                           # as these fuckers change it \n",
    "ray.shutdown()\n",
    "context = ray.init(num_cpus=10)\n",
    "print(\"Ray dashboard URL: \", context.dashboard_url)\n",
    "\n",
    "def tune_func(config):\n",
    "        tune.utils.wait_for_gpu(target_util=0.2)\n",
    "        trainer.train_from_dict(config)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping, ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if False:\n",
    "    num_samples=40\n",
    "    max_num_epochs=4*nt_h.log_val_freq # it is not num epochs, but how often we calculae val loss (we can also calc it mid epoch) todo: make it more logical\n",
    "    gpus_per_trial = 1\n",
    "    \n",
    "    scheduler = ASHAScheduler(\n",
    "            metric=\"loss\",\n",
    "            mode=\"min\",\n",
    "            max_t=max_num_epochs,\n",
    "            grace_period=1,\n",
    "            reduction_factor=2,\n",
    "        )\n",
    "    \n",
    "    def tune_func(config):\n",
    "        tune.utils.wait_for_gpu(target_util=0.2)\n",
    "        trainer.train_from_dict(config)\n",
    "    \n",
    "    result = tune.run(\n",
    "            tune_func,\n",
    "            resources_per_trial={\"cpu\": 10, \"gpu\": gpus_per_trial},\n",
    "            config=config,\n",
    "            num_samples=num_samples,\n",
    "            scheduler=scheduler,\n",
    "    \n",
    "            raise_on_failed_trial=False,\n",
    "        )\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOHB (Bayesian Optimization HyperBand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 15:47:31,791\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to sample a configuration from TuneBOHB, but the `metric` (None) or `mode` (None) parameters have not been set. Either pass these arguments when instantiating the search algorithm, or pass them to `tune.TuneConfig()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 19\u001b[0m\n\u001b[1;32m     11\u001b[0m search_alg \u001b[38;5;241m=\u001b[39m TuneBOHB()\n\u001b[1;32m     12\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m HyperBandForBOHB(metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m             mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m             max_t\u001b[38;5;241m=\u001b[39mmax_num_epochs, \u001b[38;5;66;03m# Maximum number of iterations\u001b[39;00m\n\u001b[1;32m     15\u001b[0m             reduction_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;66;03m# Reduce trials by a factor of 2 at each stage\u001b[39;00m\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 19\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtune_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_alg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_alg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Typically requires more samples to be effective\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraise_on_failed_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresources_per_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpus_per_trial\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/tune.py:994\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, resume_config, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mis_finished() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m experiment_interrupted_event\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[0;32m--> 994\u001b[0m         \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    995\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m has_verbosity(Verbosity\u001b[38;5;241m.\u001b[39mV1_EXPERIMENT):\n\u001b[1;32m    996\u001b[0m             _report_progress(runner, progress_reporter)\n",
      "File \u001b[0;32m~/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/execution/tune_controller.py:679\u001b[0m, in \u001b[0;36mTuneController.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callbacks\u001b[38;5;241m.\u001b[39mon_step_begin(\n\u001b[1;32m    675\u001b[0m         iteration\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iteration, trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trials\n\u001b[1;32m    676\u001b[0m     )\n\u001b[1;32m    678\u001b[0m \u001b[38;5;66;03m# Ask searcher for more trials\u001b[39;00m\n\u001b[0;32m--> 679\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_update_trial_queue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;66;03m# Start actors for added trials\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_add_actors()\n",
      "File \u001b[0;32m~/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/execution/tune_controller.py:779\u001b[0m, in \u001b[0;36mTuneController._maybe_update_trial_queue\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    774\u001b[0m dont_wait_for_trial \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pending_trials \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_trials \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_paused_trials\n\u001b[1;32m    776\u001b[0m )\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pending_trials) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_pending_trials:\n\u001b[0;32m--> 779\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_trial_queue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdont_wait_for_trial\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    780\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     dont_wait_for_trial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/execution/tune_controller.py:568\u001b[0m, in \u001b[0;36mTuneController._update_trial_queue\u001b[0;34m(self, blocking, timeout)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_trial_queue\u001b[39m(\u001b[38;5;28mself\u001b[39m, blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, timeout: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m600\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    556\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Adds next trials to queue if possible.\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \n\u001b[1;32m    558\u001b[0m \u001b[38;5;124;03m    Note that the timeout is currently unexposed to the user.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;124;03m        Boolean indicating if a new trial was created or not.\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 568\u001b[0m     trial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_search_alg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m blocking \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trial:\n\u001b[1;32m    570\u001b[0m         start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/search/search_generator.py:99\u001b[0m, in \u001b[0;36mSearchGenerator.next_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Provides one Trial object to be queued into the TrialRunner.\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    Trial: Returns a single trial.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_finished():\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_trial_if_possible\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_experiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/search/search_generator.py:105\u001b[0m, in \u001b[0;36mSearchGenerator.create_trial_if_possible\u001b[0;34m(self, experiment_spec)\u001b[0m\n\u001b[1;32m    103\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreating trial\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m trial_id \u001b[38;5;241m=\u001b[39m Trial\u001b[38;5;241m.\u001b[39mgenerate_id()\n\u001b[0;32m--> 105\u001b[0m suggested_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m suggested_config \u001b[38;5;241m==\u001b[39m Searcher\u001b[38;5;241m.\u001b[39mFINISHED:\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finished \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/search/bohb/bohb_search.py:223\u001b[0m, in \u001b[0;36mTuneBOHB.suggest\u001b[0;34m(self, trial_id)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    217\u001b[0m         UNDEFINED_SEARCH_SPACE\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    218\u001b[0m             \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, space\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspace\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         )\n\u001b[1;32m    220\u001b[0m     )\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metric \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode:\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    224\u001b[0m         UNDEFINED_METRIC_MODE\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metric, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[1;32m    226\u001b[0m         )\n\u001b[1;32m    227\u001b[0m     )\n\u001b[1;32m    229\u001b[0m max_concurrent \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_concurrent \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_concurrent \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m max_concurrent:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to sample a configuration from TuneBOHB, but the `metric` (None) or `mode` (None) parameters have not been set. Either pass these arguments when instantiating the search algorithm, or pass them to `tune.TuneConfig()`."
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    from ray.tune.schedulers import HyperBandForBOHB\n",
    "    from ray.tune.search.bohb import TuneBOHB\n",
    "    \n",
    "    \n",
    "    num_samples=100\n",
    "    max_num_epochs=10*nt_h.log_val_freq # it is not num epochs, but how often we calculae val loss (we can also calc it mid epoch) todo: make it more logical\n",
    "    gpus_per_trial = 1\n",
    "        \n",
    "    \n",
    "    search_alg = TuneBOHB()\n",
    "    scheduler = HyperBandForBOHB(\n",
    "                metric=\"loss\",\n",
    "                mode=\"min\",\n",
    "                max_t=max_num_epochs, # Maximum number of iterations\n",
    "                reduction_factor=2, # Reduce trials by a factor of 2 at each stage\n",
    "    )\n",
    "\n",
    "\n",
    "    result = tune.run(\n",
    "        tune_func,\n",
    "        config=config,\n",
    "        search_alg=search_alg,\n",
    "        scheduler=scheduler,\n",
    "        num_samples=num_samples,  # Typically requires more samples to be effective\n",
    "        raise_on_failed_trial=False,\n",
    "        resources_per_trial={\"cpu\": 10, \"gpu\": gpus_per_trial},\n",
    "    \n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "print(f\"Best trial config: {best_trial.config}\")\n",
    "print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
