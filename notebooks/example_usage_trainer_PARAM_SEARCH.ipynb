{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage of trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload after code has changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first time, moving up one dir level\n",
      "This path should be the root directory of the project:  /home/daniel/Documents/TUM/ADLR/tum-adlr-02\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# move into the correct dirrectory, e.g. move up one directory level iif this cell is run for the first time\n",
    "try:\n",
    "    a = first_time\n",
    "except NameError:\n",
    "    print(\"Running first time, moving up one dir level\")\n",
    "    os.chdir('..')  # Move up one directory level to the root directory of project\n",
    "    first_time = False\n",
    "\n",
    "print(\"This path should be the root directory of the project: \", os.getcwd())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset\n",
    "Creating the dataset object and applzing transformations to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.model_classes import Mug, Bottle\n",
    "from data.dataconverter import DataConverter\n",
    "\n",
    "# generate data\n",
    "dataconverter = DataConverter(\n",
    "    classes=[Mug(),Bottle()],\n",
    "    min_order = 1,\n",
    "    tact_order = 10,\n",
    "    tact_number=2, \n",
    "    rand_rotations=2\n",
    "    \n",
    ")\n",
    "# set regenerate to true, if you run this after changes in dataconverter have been made\n",
    "#dataconverter.generate_2d_dataset(show_results=False, regenerate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.reconstruction_dataset import *\n",
    "\n",
    "csv_file = './datasets/2D_shapes/annotations.csv'\n",
    "root_dir = './datasets/2D_shapes'\n",
    "composed = transforms.Compose([RandomOrientation(),\n",
    "                               ToTensor()])\n",
    "\n",
    "dataset = ReconstructionDataset(csv_file=csv_file,\n",
    "                                root_dir=root_dir,\n",
    "                                transform=composed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examplary data pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_data = dataset[5]\n",
    "\n",
    "plt.figure()\n",
    "print(example_data['image'])\n",
    "show_datapair(example_data['image'], example_data['label'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Hyperparamters\n",
    "\n",
    "Look into the file neural_nets.trainer to see which hyperparameters you can choose.\n",
    "The seperation into tunable and non tunable hyperparameters is made, because this makes parameter searches with ray easier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non Tunable Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_nets.trainer import NonTHparams\n",
    "\n",
    "\n",
    "nt_h = NonTHparams()\n",
    "nt_h.num_epochs = 50\n",
    "nt_h.train_prop = 0.93 # set way to high to make validation period short and make testing this search easier\n",
    "\n",
    "nt_h.print_log = True # to better see param search results\n",
    "nt_h.log_train_period = 100\n",
    "nt_h.log_val_freq = 5 #int(nt_h.train_prop*len(dataset)/f)-1 #set low to test this parameter search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Tunable Hyperparameters and parameter spaces for upgrade\n",
    "\n",
    "The hyperparameters we want to tone have to be put into a list of possible values and that list into a dict, for the hyperparameter optimizer to do its job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from neural_nets.trainer import THparams\n",
    "from neural_nets.weight_inits import weight_init_kx\n",
    "from neural_nets.models.unet import UNet2\n",
    "\n",
    "\n",
    "from ray import tune\n",
    "from ray import train\n",
    "from ray.train import Checkpoint, get_checkpoint\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import ray.cloudpickle as pickle\n",
    "\n",
    "t_h = THparams()\n",
    "t_h.batch_size = 16\n",
    "\n",
    "t_h.model = UNet2\n",
    "t_h.weight_init = weight_init_kx\n",
    "t_h.depth = 5\n",
    "t_h.channels = 64\n",
    "\n",
    "t_h.lr = 1e-4\n",
    "t_h.optimizer = optim.Adam\n",
    "t_h.loss_func = nn.BCELoss()\n",
    "\n",
    "\n",
    "image_resolution = dataset[0]['image'].shape[1]\n",
    "max_unet_depth = int(np.log2(image_resolution))\n",
    "\n",
    "# config is the set of params, that will be searched, they got to ghave the same key names, as variables in THparams\n",
    "config = {\n",
    "    \"batch_size\": tune.choice([2 ** i for i in range(2,5)]),\n",
    "    \"lr\": tune.loguniform(1e-7, 1e-2),\n",
    "    \"depth\": tune.choice([i for i in range(3,max_unet_depth+1-2)]),\n",
    "    \"channels\": tune.choice([2 ** i for i in range(4,9)])\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During training, progress will be logged to tensorboard. Go to project folder, activate appropritae conda environment and run 'tensorboard --logdir runs/' to see the logs.\n"
     ]
    }
   ],
   "source": [
    "from neural_nets.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(nt_h, t_h, dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 02:57:17,908\tINFO worker.py:1761 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2024-06-23 02:57:18,736\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray dashboard URL:  127.0.0.1:8265\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-06-23 03:04:19</td></tr>\n",
       "<tr><td>Running for: </td><td>00:07:00.53        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.5/15.6 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -0.6603025192708041<br>Logical resource usage: 10.0/10 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  ... 20 more trials not shown (20 PENDING)\n",
       "  Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                                       </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>tune_func_8a568_00000</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-06-23_02-57-15_327519_61335/artifacts/2024-06-23_02-57-18/tune_func_2024-06-23_02-57-18/driver_artifacts/tune_func_8a568_00000_0_batch_size=16,channels=128,depth=3,lr=0.0000_2024-06-23_02-57-19/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  channels</th><th style=\"text-align: right;\">  depth</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>tune_func_8a568_00001</td><td>RUNNING </td><td>192.168.42.46:65711</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">        16</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">1.03161e-07</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_func_8a568_00002</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">        32</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">5.38277e-06</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_func_8a568_00003</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">        32</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">0.0062986  </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_func_8a568_00004</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">       128</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">0.000452809</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_func_8a568_00005</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">        16</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">5.94025e-06</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_func_8a568_00006</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">        16</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">2.08042e-07</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_func_8a568_00007</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">       128</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">0.00505805 </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_func_8a568_00008</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">        16</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">6.7184e-08 </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_func_8a568_00009</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">       128</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">2.17176e-06</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_func_8a568_00010</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">       128</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">5.45071e-09</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_func_8a568_00011</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">       128</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">2.25907e-06</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_func_8a568_00012</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">       128</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">5.11884e-08</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_func_8a568_00013</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">        16</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">8.50939e-06</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_func_8a568_00014</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">       128</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">2.63578e-07</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_func_8a568_00015</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">        16</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">0.000186177</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_func_8a568_00016</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">        32</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">0.000643645</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_func_8a568_00017</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">2.49458e-09</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_func_8a568_00018</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">        64</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">7.27491e-07</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_func_8a568_00019</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">1.24207e-07</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_func_8a568_00000</td><td>ERROR   </td><td>192.168.42.46:65008</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">       128</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">3.23733e-07</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         399.118</td><td style=\"text-align: right;\">0.660303</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(tune_func pid=65008)\u001b[0m Hurray! GPU available.\n",
      "\u001b[36m(tune_func pid=65008)\u001b[0m Total trainable parameters: 7066113\n",
      "\u001b[36m(tune_func pid=65008)\u001b[0m Epoch [1/50], Step [100/1491], Train Loss: 0.6897 , Logging Time Proportion: 0.0008, Data Loading Time Proportion: 0.0012\n",
      "\u001b[36m(tune_func pid=65008)\u001b[0m Epoch [1/50], Step [200/1491], Train Loss: 0.6811 , Logging Time Proportion: 0.0001, Data Loading Time Proportion: 0.0013\n",
      "\u001b[36m(tune_func pid=65008)\u001b[0m #######################################################################################\n",
      "\u001b[36m(tune_func pid=65008)\u001b[0m Epoch [1/50], Step [6/1491], Val Loss: 0.6603 Val Log Time Proportion: 0.1437\n",
      "\u001b[36m(tune_func pid=65008)\u001b[0m #######################################################################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th style=\"text-align: right;\">    loss</th><th>should_checkpoint  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>tune_func_8a568_00000</td><td style=\"text-align: right;\">0.660303</td><td>True               </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(tune_func pid=65008)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/daniel/ray_results/tune_func_2024-06-23_02-57-18/tune_func_8a568_00000_0_batch_size=16,channels=128,depth=3,lr=0.0000_2024-06-23_02-57-19/checkpoint_000000)\n",
      "2024-06-23 03:04:03,881\tERROR tune_controller.py:1331 -- Trial task failed for trial tune_func_8a568_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 2630, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 863, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(OutOfMemoryError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=65008, ip=192.168.42.46, actor_id=292a77b81075e7dfff8084ef01000000, repr=tune_func)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_61335/815730020.py\", line 25, in tune_func\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 131, in train_from_dict\n",
      "    self.train()\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 211, in train\n",
      "    outputs = model(inputs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/models/unet.py\", line 71, in forward\n",
      "    bottleneck = decode(bottleneck + enc_outputs[-(i + 1)])\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 952, in forward\n",
      "    return F.conv_transpose2d(\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB. GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(tune_func pid=65711)\u001b[0m Hurray! GPU available.\n",
      "\u001b[36m(tune_func pid=65711)\u001b[0m Total trainable parameters: 110913\n",
      "\u001b[36m(tune_func pid=65711)\u001b[0m Epoch [1/50], Step [100/5961], Train Loss: 0.6931 , Logging Time Proportion: 0.0037, Data Loading Time Proportion: 0.0071\n",
      "\u001b[36m(tune_func pid=65711)\u001b[0m Epoch [1/50], Step [200/5961], Train Loss: 0.6930 , Logging Time Proportion: 0.0030, Data Loading Time Proportion: 0.0078\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import GPUtil\n",
    "\n",
    "num_samples=40\n",
    "max_num_epochs=4*nt_h.log_val_freq # it is not num epochs, but how often we calculae val loss (we can also calc it mid epoch) todo: make it more logical\n",
    "gpus_per_trial = 1\n",
    "\n",
    "os.environ[\"RAY_CHDIR_TO_TRIAL_DIR\"] = \"0\" # needed so that we still can load files using path relative to working directory, \n",
    "                                           # as these fuckers change it \n",
    "ray.shutdown()\n",
    "context = ray.init(num_cpus=10)\n",
    "print(\"Ray dashboard URL: \", context.dashboard_url)\n",
    "\n",
    "\n",
    "scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2,\n",
    "    )\n",
    "\n",
    "def tune_func(config):\n",
    "    tune.utils.wait_for_gpu(target_util=0.2)\n",
    "    trainer.train_from_dict(config)\n",
    "\n",
    "result = tune.run(\n",
    "        tune_func,\n",
    "        resources_per_trial={\"cpu\": 10, \"gpu\": gpus_per_trial},\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "\n",
    "        raise_on_failed_trial=False,\n",
    "    )\n",
    "\n",
    "best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "print(f\"Best trial config: {best_trial.config}\")\n",
    "print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")\n",
    "print(f\"Best trial final validation accuracy: {best_trial.last_result['accuracy']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
