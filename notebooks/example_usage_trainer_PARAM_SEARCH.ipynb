{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage of trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload after code has changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first time, moving up one dir level\n",
      "This path should be the root directory of the project:  /home/daniel/Documents/TUM/ADLR/tum-adlr-02\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# move into the correct dirrectory, e.g. move up one directory level iif this cell is run for the first time\n",
    "try:\n",
    "    a = first_time\n",
    "except NameError:\n",
    "    print(\"Running first time, moving up one dir level\")\n",
    "    os.chdir('..')  # Move up one directory level to the root directory of project\n",
    "    first_time = False\n",
    "\n",
    "print(\"This path should be the root directory of the project: \", os.getcwd())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset\n",
    "Creating the dataset object and applzing transformations to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.model_classes import Mug, Bottle\n",
    "from data.dataconverter import DataConverter\n",
    "\n",
    "# generate data\n",
    "dataconverter = DataConverter(\n",
    "    classes=[Mug(),Bottle()],\n",
    "    min_order = 1,\n",
    "    tact_order = 10,\n",
    "    tact_number=2, \n",
    "    rand_rotations=2\n",
    "    \n",
    ")\n",
    "# set regenerate to true, if you run this after changes in dataconverter have been made\n",
    "#dataconverter.generate_2d_dataset(show_results=False, regenerate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.reconstruction_dataset import *\n",
    "\n",
    "csv_file = './datasets/2D_shapes/annotations.csv'\n",
    "root_dir = './datasets/2D_shapes'\n",
    "composed = transforms.Compose([RandomOrientation(),\n",
    "                               ToTensor()])\n",
    "\n",
    "dataset = ReconstructionDataset(csv_file=csv_file,\n",
    "                                root_dir=root_dir,\n",
    "                                transform=composed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examplary data pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_data = dataset[5]\n",
    "\n",
    "plt.figure()\n",
    "print(example_data['image'])\n",
    "show_datapair(example_data['image'], example_data['label'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Hyperparamters\n",
    "\n",
    "Look into the file neural_nets.trainer to see which hyperparameters you can choose.\n",
    "The seperation into tunable and non tunable hyperparameters is made, because this makes parameter searches with ray easier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non Tunable Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_nets.trainer import NonTHparams\n",
    "\n",
    "\n",
    "nt_h = NonTHparams()\n",
    "nt_h.num_epochs = 50\n",
    "nt_h.train_prop = 0.93 # set way to high to make validation period short and make testing this search easier\n",
    "\n",
    "nt_h.print_log = True # to better see param search results\n",
    "nt_h.log_train_period = 100\n",
    "nt_h.log_val_freq = 5 #int(nt_h.train_prop*len(dataset)/f)-1 #set low to test this parameter search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Tunable Hyperparameters and parameter spaces for upgrade\n",
    "\n",
    "The hyperparameters we want to tone have to be put into a list of possible values and that list into a dict, for the hyperparameter optimizer to do its job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from neural_nets.trainer import THparams\n",
    "from neural_nets.weight_inits import weight_init_kx\n",
    "from neural_nets.models.unet import UNet2\n",
    "\n",
    "\n",
    "from ray import tune\n",
    "from ray import train\n",
    "from ray.train import Checkpoint, get_checkpoint\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import ray.cloudpickle as pickle\n",
    "\n",
    "t_h = THparams()\n",
    "t_h.batch_size = 16\n",
    "\n",
    "t_h.model = UNet2\n",
    "t_h.weight_init = weight_init_kx\n",
    "t_h.depth = 5\n",
    "t_h.channels = 64\n",
    "\n",
    "t_h.lr = 1e-4\n",
    "t_h.optimizer = optim.Adam\n",
    "t_h.loss_func = nn.BCELoss()\n",
    "\n",
    "\n",
    "image_resolution = dataset[0]['image'].shape[1]\n",
    "max_unet_depth = int(np.log2(image_resolution))\n",
    "\n",
    "# config is the set of params, that will be searched, they got to ghave the same key names, as variables in THparams\n",
    "config = {\n",
    "    \"batch_size\": tune.choice([2 ** i for i in range(2,5)]),\n",
    "    \"lr\": tune.loguniform(1e-9, 1e-2),\n",
    "    \"depth\": tune.choice([i for i in range(3,max_unet_depth+1-2)]),\n",
    "    \"channels\": tune.choice([2 ** i for i in range(4,9)])\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During training, progress will be logged to tensorboard. Go to project folder, activate appropritae conda environment and run 'tensorboard --logdir runs/' to see the logs.\n"
     ]
    }
   ],
   "source": [
    "from neural_nets.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(nt_h, t_h, dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 02:48:59,048\tINFO worker.py:1761 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2024-06-23 02:48:59,798\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray dashboard URL:  127.0.0.1:8265\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-06-23 02:56:20</td></tr>\n",
       "<tr><td>Running for: </td><td>00:07:20.68        </td></tr>\n",
       "<tr><td>Memory:      </td><td>5.8/15.6 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None<br>Logical resource usage: 10.0/10 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  ... 20 more trials not shown (16 PENDING, 4 ERROR)\n",
       "  Number of errored trials: 14<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                                       </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>tune_func_60f44_00000</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-06-23_02-48-54_192007_61335/artifacts/2024-06-23_02-48-59/tune_func_2024-06-23_02-48-59/driver_artifacts/tune_func_60f44_00000_0_batch_size=16,channels=256,depth=3,lr=0.0000_2024-06-23_02-49-00/error.txt</td></tr>\n",
       "<tr><td>tune_func_60f44_00001</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-06-23_02-48-54_192007_61335/artifacts/2024-06-23_02-48-59/tune_func_2024-06-23_02-48-59/driver_artifacts/tune_func_60f44_00001_1_batch_size=16,channels=64,depth=4,lr=0.0000_2024-06-23_02-49-00/error.txt </td></tr>\n",
       "<tr><td>tune_func_60f44_00002</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-06-23_02-48-54_192007_61335/artifacts/2024-06-23_02-48-59/tune_func_2024-06-23_02-48-59/driver_artifacts/tune_func_60f44_00002_2_batch_size=8,channels=64,depth=4,lr=0.0000_2024-06-23_02-49-00/error.txt  </td></tr>\n",
       "<tr><td>tune_func_60f44_00003</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-06-23_02-48-54_192007_61335/artifacts/2024-06-23_02-48-59/tune_func_2024-06-23_02-48-59/driver_artifacts/tune_func_60f44_00003_3_batch_size=16,channels=128,depth=4,lr=0.0028_2024-06-23_02-49-00/error.txt</td></tr>\n",
       "<tr><td>tune_func_60f44_00004</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-06-23_02-48-54_192007_61335/artifacts/2024-06-23_02-48-59/tune_func_2024-06-23_02-48-59/driver_artifacts/tune_func_60f44_00004_4_batch_size=16,channels=64,depth=4,lr=0.0030_2024-06-23_02-49-00/error.txt </td></tr>\n",
       "<tr><td>tune_func_60f44_00005</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-06-23_02-48-54_192007_61335/artifacts/2024-06-23_02-48-59/tune_func_2024-06-23_02-48-59/driver_artifacts/tune_func_60f44_00005_5_batch_size=8,channels=16,depth=4,lr=0.0000_2024-06-23_02-49-00/error.txt  </td></tr>\n",
       "<tr><td>tune_func_60f44_00006</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-06-23_02-48-54_192007_61335/artifacts/2024-06-23_02-48-59/tune_func_2024-06-23_02-48-59/driver_artifacts/tune_func_60f44_00006_6_batch_size=4,channels=16,depth=4,lr=0.0002_2024-06-23_02-49-00/error.txt  </td></tr>\n",
       "<tr><td>tune_func_60f44_00007</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-06-23_02-48-54_192007_61335/artifacts/2024-06-23_02-48-59/tune_func_2024-06-23_02-48-59/driver_artifacts/tune_func_60f44_00007_7_batch_size=4,channels=16,depth=6,lr=0.0000_2024-06-23_02-49-00/error.txt  </td></tr>\n",
       "<tr><td>tune_func_60f44_00008</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-06-23_02-48-54_192007_61335/artifacts/2024-06-23_02-48-59/tune_func_2024-06-23_02-48-59/driver_artifacts/tune_func_60f44_00008_8_batch_size=8,channels=128,depth=3,lr=0.0000_2024-06-23_02-49-00/error.txt </td></tr>\n",
       "<tr><td>tune_func_60f44_00009</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-06-23_02-48-54_192007_61335/artifacts/2024-06-23_02-48-59/tune_func_2024-06-23_02-48-59/driver_artifacts/tune_func_60f44_00009_9_batch_size=4,channels=64,depth=3,lr=0.0001_2024-06-23_02-49-00/error.txt  </td></tr>\n",
       "<tr><td>tune_func_60f44_00010</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-06-23_02-48-54_192007_61335/artifacts/2024-06-23_02-48-59/tune_func_2024-06-23_02-48-59/driver_artifacts/tune_func_60f44_00010_10_batch_size=4,channels=256,depth=4,lr=0.0000_2024-06-23_02-49-00/error.txt</td></tr>\n",
       "<tr><td>tune_func_60f44_00011</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-06-23_02-48-54_192007_61335/artifacts/2024-06-23_02-48-59/tune_func_2024-06-23_02-48-59/driver_artifacts/tune_func_60f44_00011_11_batch_size=8,channels=32,depth=6,lr=0.0000_2024-06-23_02-49-00/error.txt </td></tr>\n",
       "<tr><td>tune_func_60f44_00012</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-06-23_02-48-54_192007_61335/artifacts/2024-06-23_02-48-59/tune_func_2024-06-23_02-48-59/driver_artifacts/tune_func_60f44_00012_12_batch_size=16,channels=16,depth=4,lr=0.0000_2024-06-23_02-49-00/error.txt</td></tr>\n",
       "<tr><td>tune_func_60f44_00013</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-06-23_02-48-54_192007_61335/artifacts/2024-06-23_02-48-59/tune_func_2024-06-23_02-48-59/driver_artifacts/tune_func_60f44_00013_13_batch_size=8,channels=128,depth=6,lr=0.0000_2024-06-23_02-49-00/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  channels</th><th style=\"text-align: right;\">  depth</th><th style=\"text-align: right;\">         lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>tune_func_60f44_00014</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">4.77059e-09</td></tr>\n",
       "<tr><td>tune_func_60f44_00015</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">        16</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">6.67346e-08</td></tr>\n",
       "<tr><td>tune_func_60f44_00016</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">        32</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">8.92784e-07</td></tr>\n",
       "<tr><td>tune_func_60f44_00017</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">        64</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">1.791e-09  </td></tr>\n",
       "<tr><td>tune_func_60f44_00018</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">1.76672e-05</td></tr>\n",
       "<tr><td>tune_func_60f44_00019</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">        16</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">5.59629e-07</td></tr>\n",
       "<tr><td>tune_func_60f44_00020</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">2.13744e-09</td></tr>\n",
       "<tr><td>tune_func_60f44_00021</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">        16</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">7.79465e-07</td></tr>\n",
       "<tr><td>tune_func_60f44_00022</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">       128</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">2.42996e-06</td></tr>\n",
       "<tr><td>tune_func_60f44_00023</td><td>PENDING </td><td>                   </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">        64</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">3.20736e-07</td></tr>\n",
       "<tr><td>tune_func_60f44_00000</td><td>ERROR   </td><td>192.168.42.46:62121</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">       256</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">4.362e-09  </td></tr>\n",
       "<tr><td>tune_func_60f44_00001</td><td>ERROR   </td><td>192.168.42.46:62255</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">        64</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">1.26295e-06</td></tr>\n",
       "<tr><td>tune_func_60f44_00002</td><td>ERROR   </td><td>192.168.42.46:62416</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">        64</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">6.47895e-07</td></tr>\n",
       "<tr><td>tune_func_60f44_00003</td><td>ERROR   </td><td>192.168.42.46:62573</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">       128</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">0.00277455 </td></tr>\n",
       "<tr><td>tune_func_60f44_00004</td><td>ERROR   </td><td>192.168.42.46:62692</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">        64</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">0.00303639 </td></tr>\n",
       "<tr><td>tune_func_60f44_00005</td><td>ERROR   </td><td>192.168.42.46:62849</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">        16</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">2.56453e-08</td></tr>\n",
       "<tr><td>tune_func_60f44_00006</td><td>ERROR   </td><td>192.168.42.46:62986</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">        16</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">0.00016735 </td></tr>\n",
       "<tr><td>tune_func_60f44_00007</td><td>ERROR   </td><td>192.168.42.46:63108</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">        16</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">5.16813e-08</td></tr>\n",
       "<tr><td>tune_func_60f44_00008</td><td>ERROR   </td><td>192.168.42.46:63244</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">       128</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">2.08102e-07</td></tr>\n",
       "<tr><td>tune_func_60f44_00009</td><td>ERROR   </td><td>192.168.42.46:63416</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">        64</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">0.000118704</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(tune_func pid=62121)\u001b[0m Hurray! GPU available.\n",
      "\u001b[36m(tune_func pid=62121)\u001b[0m Total trainable parameters: 28255233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 02:49:06,838\tERROR tune_controller.py:1331 -- Trial task failed for trial tune_func_60f44_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 2630, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 863, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(OutOfMemoryError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=62121, ip=192.168.42.46, actor_id=b1357f970e65280208de1d7f01000000, repr=tune_func)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_61335/815730020.py\", line 25, in tune_func\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 131, in train_from_dict\n",
      "    self.train()\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 211, in train\n",
      "    outputs = model(inputs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/models/unet.py\", line 74, in forward\n",
      "    dec0 = self.final_block(bottleneck)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 952, in forward\n",
      "    return F.conv_transpose2d(\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1024.00 MiB. GPU\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>tune_func_60f44_00000</td></tr>\n",
       "<tr><td>tune_func_60f44_00001</td></tr>\n",
       "<tr><td>tune_func_60f44_00002</td></tr>\n",
       "<tr><td>tune_func_60f44_00003</td></tr>\n",
       "<tr><td>tune_func_60f44_00004</td></tr>\n",
       "<tr><td>tune_func_60f44_00005</td></tr>\n",
       "<tr><td>tune_func_60f44_00006</td></tr>\n",
       "<tr><td>tune_func_60f44_00007</td></tr>\n",
       "<tr><td>tune_func_60f44_00008</td></tr>\n",
       "<tr><td>tune_func_60f44_00009</td></tr>\n",
       "<tr><td>tune_func_60f44_00010</td></tr>\n",
       "<tr><td>tune_func_60f44_00011</td></tr>\n",
       "<tr><td>tune_func_60f44_00012</td></tr>\n",
       "<tr><td>tune_func_60f44_00013</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(tune_func pid=62255)\u001b[0m Hurray! GPU available.\n",
      "\u001b[36m(tune_func pid=62255)\u001b[0m Total trainable parameters: 7012353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 02:50:00,661\tERROR tune_controller.py:1331 -- Trial task failed for trial tune_func_60f44_00001\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 2630, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 863, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=62255, ip=192.168.42.46, actor_id=8880d9f7e772057c22b4912401000000, repr=tune_func)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_61335/815730020.py\", line 25, in tune_func\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 131, in train_from_dict\n",
      "    self.train()\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 227, in train\n",
      "    epoch * len(train_loader) + i*self.nt_h.batch_size)\n",
      "AttributeError: 'NonTHparams' object has no attribute 'batch_size'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(tune_func pid=62416)\u001b[0m Hurray! GPU available.\n",
      "\u001b[36m(tune_func pid=62416)\u001b[0m Total trainable parameters: 7012353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 02:50:30,066\tERROR tune_controller.py:1331 -- Trial task failed for trial tune_func_60f44_00002\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 2630, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 863, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=62416, ip=192.168.42.46, actor_id=3df1923e82c4e079ed756e9701000000, repr=tune_func)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_61335/815730020.py\", line 25, in tune_func\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 131, in train_from_dict\n",
      "    self.train()\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 227, in train\n",
      "    epoch * len(train_loader) + i*self.nt_h.batch_size)\n",
      "AttributeError: 'NonTHparams' object has no attribute 'batch_size'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(tune_func pid=62573)\u001b[0m Hurray! GPU available.\n",
      "\u001b[36m(tune_func pid=62573)\u001b[0m Total trainable parameters: 28041217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 02:50:37,307\tERROR tune_controller.py:1331 -- Trial task failed for trial tune_func_60f44_00003\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 2630, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 863, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(OutOfMemoryError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=62573, ip=192.168.42.46, actor_id=0bada5c3d997e343812a8a9901000000, repr=tune_func)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_61335/815730020.py\", line 25, in tune_func\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 131, in train_from_dict\n",
      "    self.train()\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 213, in train\n",
      "    loss.backward()\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/torch/_tensor.py\", line 525, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/torch/autograd/__init__.py\", line 267, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/torch/autograd/graph.py\", line 744, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 512.00 MiB. GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(tune_func pid=62692)\u001b[0m Hurray! GPU available.\n",
      "\u001b[36m(tune_func pid=62692)\u001b[0m Total trainable parameters: 7012353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 02:51:29,208\tERROR tune_controller.py:1331 -- Trial task failed for trial tune_func_60f44_00004\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 2630, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 863, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=62692, ip=192.168.42.46, actor_id=d5c8cca5e56463351893a7d201000000, repr=tune_func)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_61335/815730020.py\", line 25, in tune_func\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 131, in train_from_dict\n",
      "    self.train()\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 227, in train\n",
      "    epoch * len(train_loader) + i*self.nt_h.batch_size)\n",
      "AttributeError: 'NonTHparams' object has no attribute 'batch_size'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(tune_func pid=62849)\u001b[0m Hurray! GPU available.\n",
      "\u001b[36m(tune_func pid=62849)\u001b[0m Total trainable parameters: 439041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 02:51:45,311\tERROR tune_controller.py:1331 -- Trial task failed for trial tune_func_60f44_00005\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 2630, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 863, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=62849, ip=192.168.42.46, actor_id=d1d2987084dd0bfb49146a3f01000000, repr=tune_func)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_61335/815730020.py\", line 25, in tune_func\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 131, in train_from_dict\n",
      "    self.train()\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 227, in train\n",
      "    epoch * len(train_loader) + i*self.nt_h.batch_size)\n",
      "AttributeError: 'NonTHparams' object has no attribute 'batch_size'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(tune_func pid=62986)\u001b[0m Hurray! GPU available.\n",
      "\u001b[36m(tune_func pid=62986)\u001b[0m Total trainable parameters: 439041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 02:51:56,622\tERROR tune_controller.py:1331 -- Trial task failed for trial tune_func_60f44_00006\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 2630, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 863, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=62986, ip=192.168.42.46, actor_id=894aeac53536d0338cb260f901000000, repr=tune_func)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_61335/815730020.py\", line 25, in tune_func\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 131, in train_from_dict\n",
      "    self.train()\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 227, in train\n",
      "    epoch * len(train_loader) + i*self.nt_h.batch_size)\n",
      "AttributeError: 'NonTHparams' object has no attribute 'batch_size'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(tune_func pid=63108)\u001b[0m Hurray! GPU available.\n",
      "\u001b[36m(tune_func pid=63108)\u001b[0m Total trainable parameters: 6995329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 02:52:10,879\tERROR tune_controller.py:1331 -- Trial task failed for trial tune_func_60f44_00007\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 2630, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 863, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=63108, ip=192.168.42.46, actor_id=5bc9cc6890a9c204065ff48801000000, repr=tune_func)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_61335/815730020.py\", line 25, in tune_func\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 131, in train_from_dict\n",
      "    self.train()\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 227, in train\n",
      "    epoch * len(train_loader) + i*self.nt_h.batch_size)\n",
      "AttributeError: 'NonTHparams' object has no attribute 'batch_size'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(tune_func pid=63244)\u001b[0m Hurray! GPU available.\n",
      "\u001b[36m(tune_func pid=63244)\u001b[0m Total trainable parameters: 7066113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 02:53:06,946\tERROR tune_controller.py:1331 -- Trial task failed for trial tune_func_60f44_00008\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 2630, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 863, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=63244, ip=192.168.42.46, actor_id=ce9becf78fa28482e3094b4801000000, repr=tune_func)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_61335/815730020.py\", line 25, in tune_func\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 131, in train_from_dict\n",
      "    self.train()\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 227, in train\n",
      "    epoch * len(train_loader) + i*self.nt_h.batch_size)\n",
      "AttributeError: 'NonTHparams' object has no attribute 'batch_size'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(tune_func pid=63416)\u001b[0m Hurray! GPU available.\n",
      "\u001b[36m(tune_func pid=63416)\u001b[0m Total trainable parameters: 1767681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 02:53:22,568\tERROR tune_controller.py:1331 -- Trial task failed for trial tune_func_60f44_00009\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 2630, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 863, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=63416, ip=192.168.42.46, actor_id=061e9067e680472514218c2c01000000, repr=tune_func)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_61335/815730020.py\", line 25, in tune_func\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 131, in train_from_dict\n",
      "    self.train()\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 227, in train\n",
      "    epoch * len(train_loader) + i*self.nt_h.batch_size)\n",
      "AttributeError: 'NonTHparams' object has no attribute 'batch_size'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(tune_func pid=63550)\u001b[0m Hurray! GPU available.\n",
      "\u001b[36m(tune_func pid=63550)\u001b[0m Total trainable parameters: 112148481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 02:55:17,911\tERROR tune_controller.py:1331 -- Trial task failed for trial tune_func_60f44_00010\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 2630, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 863, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=63550, ip=192.168.42.46, actor_id=04799102ed2e047edc7f568e01000000, repr=tune_func)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_61335/815730020.py\", line 25, in tune_func\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 131, in train_from_dict\n",
      "    self.train()\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 227, in train\n",
      "    epoch * len(train_loader) + i*self.nt_h.batch_size)\n",
      "AttributeError: 'NonTHparams' object has no attribute 'batch_size'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(tune_func pid=63756)\u001b[0m Hurray! GPU available.\n",
      "\u001b[36m(tune_func pid=63756)\u001b[0m Total trainable parameters: 27973889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 02:55:39,704\tERROR tune_controller.py:1331 -- Trial task failed for trial tune_func_60f44_00011\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 2630, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 863, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=63756, ip=192.168.42.46, actor_id=11f1433578f02230aca057ec01000000, repr=tune_func)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_61335/815730020.py\", line 25, in tune_func\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 131, in train_from_dict\n",
      "    self.train()\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 227, in train\n",
      "    epoch * len(train_loader) + i*self.nt_h.batch_size)\n",
      "AttributeError: 'NonTHparams' object has no attribute 'batch_size'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(tune_func pid=63897)\u001b[0m Hurray! GPU available.\n",
      "\u001b[36m(tune_func pid=63897)\u001b[0m Total trainable parameters: 439041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 02:56:02,719\tERROR tune_controller.py:1331 -- Trial task failed for trial tune_func_60f44_00012\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 2630, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 863, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=63897, ip=192.168.42.46, actor_id=1da91f13c648af44006ab6da01000000, repr=tune_func)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_61335/815730020.py\", line 25, in tune_func\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 131, in train_from_dict\n",
      "    self.train()\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 227, in train\n",
      "    epoch * len(train_loader) + i*self.nt_h.batch_size)\n",
      "AttributeError: 'NonTHparams' object has no attribute 'batch_size'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(tune_func pid=64039)\u001b[0m Hurray! GPU available.\n",
      "\u001b[36m(tune_func pid=64039)\u001b[0m Total trainable parameters: 447493121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 02:56:12,657\tERROR tune_controller.py:1331 -- Trial task failed for trial tune_func_60f44_00013\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 2630, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/_private/worker.py\", line 863, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(OutOfMemoryError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=64039, ip=192.168.42.46, actor_id=d6ad2a722434eaa41d65953f01000000, repr=tune_func)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/air/_internal/util.py\", line 98, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_61335/815730020.py\", line 25, in tune_func\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 131, in train_from_dict\n",
      "    self.train()\n",
      "  File \"/home/daniel/Documents/TUM/ADLR/tum-adlr-02/neural_nets/trainer.py\", line 214, in train\n",
      "    optimizer.step()\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 391, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/torch/optim/adam.py\", line 168, in step\n",
      "    adam(\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/torch/optim/adam.py\", line 318, in adam\n",
      "    func(params,\n",
      "  File \"/home/daniel/anaconda3/envs/adlr/lib/python3.9/site-packages/torch/optim/adam.py\", line 581, in _multi_tensor_adam\n",
      "    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 288.00 MiB. GPU\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import GPUtil\n",
    "\n",
    "num_samples=40\n",
    "max_num_epochs=4*nt_h.log_val_freq # it is not num epochs, but how often we calculae val loss (we can also calc it mid epoch) todo: make it more logical\n",
    "gpus_per_trial = 1\n",
    "\n",
    "os.environ[\"RAY_CHDIR_TO_TRIAL_DIR\"] = \"0\" # needed so that we still can load files using path relative to working directory, \n",
    "                                           # as these fuckers change it \n",
    "ray.shutdown()\n",
    "context = ray.init(num_cpus=10)\n",
    "print(\"Ray dashboard URL: \", context.dashboard_url)\n",
    "\n",
    "\n",
    "scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2,\n",
    "    )\n",
    "\n",
    "def tune_func(config):\n",
    "    tune.utils.wait_for_gpu(target_util=0.2)\n",
    "    trainer.train_from_dict(config)\n",
    "\n",
    "result = tune.run(\n",
    "        tune_func,\n",
    "        resources_per_trial={\"cpu\": 10, \"gpu\": gpus_per_trial},\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "\n",
    "        raise_on_failed_trial=False,\n",
    "    )\n",
    "\n",
    "best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "print(f\"Best trial config: {best_trial.config}\")\n",
    "print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")\n",
    "print(f\"Best trial final validation accuracy: {best_trial.last_result['accuracy']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
