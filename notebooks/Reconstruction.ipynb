{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstrution Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload after code has changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first time\n",
      "This path should be the root directory of the project:  /home/daniel/Documents/TUM/ADLR/tum-adlr-02\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# move into the correct dirrectory, e.g. move up one directory level iif this cell is run for the first time\n",
    "try:\n",
    "    a = first_time\n",
    "except NameError:\n",
    "    print(\"Running first time, moving up one dir level\")\n",
    "    os.chdir('..')  # Move up one directory level to the root directory of project\n",
    "    first_time = False\n",
    "\n",
    "print(\"This path should be the root directory of the project: \", os.getcwd())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.utils as vutils\n",
    "import datetime\n",
    "\n",
    "\n",
    "from data.model_classes import Mug, Bottle\n",
    "from data.dataconverter import DataConverter\n",
    "from data.reconstruction_dataset import *\n",
    "from models.unet import UNet1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "Creating the dataset object and applzing transformations to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class mug already downloaedd. Skipping download.\n",
      "class bottle already downloaedd. Skipping download.\n",
      "Converting  214  files ...\n",
      "Converting  498  files ...\n"
     ]
    }
   ],
   "source": [
    "# Outcommented because there are currently someproblems running it in the notebook\n",
    "\n",
    "# generate data\n",
    "dataconverter = DataConverter(\n",
    "    classes=[Mug(),Bottle()],\n",
    "    min_order = 59,\n",
    "    tact_order = 60\n",
    ")\n",
    "# set regenerate to true, if you run this after changes in dataconverter have been made\n",
    "dataconverter.generate_2d_dataset(show_results=False, regenerate=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = './datasets/2D_shapes/annotations.csv'\n",
    "root_dir = './datasets/2D_shapes'\n",
    "composed = transforms.Compose([RandomOrientation(),\n",
    "                               ToTensor()])\n",
    "\n",
    "dataset = ReconstructionDataset(csv_file=csv_file,\n",
    "                                root_dir=root_dir,\n",
    "                                transform=composed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examplary data pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_data = dataset[0]\n",
    "\n",
    "plt.figure()\n",
    "show_datapair(example_data['image'], example_data['label'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Dataset into train, validation and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sizes for train, validation, and test\n",
    "train_size = int(0.75 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "learning_rate = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader\n",
    "Creating a dataloader based on the dataset for batch processing.\n",
    "\n",
    "TODO: Remove spacing in figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 256, 256])\n",
      "torch.Size([1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/Documents/TUM/ADLR/tum-adlr-02/data/reconstruction_dataset.py:37: UserWarning: Tight layout not applied. tight_layout cannot make axes width small enough to accommodate all axes decorations\n",
      "  fig.tight_layout()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1x19096 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "print(batch['image'].shape)\n",
    "\n",
    "show_datapair_batch(next(iter(train_loader)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet1().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Set up TensorBoard\n",
    "writer = SummaryWriter(f'runs/U-Net_{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [1/668], Val Loss: 0.7451\n",
      "Epoch [2/50], Step [2/668], Val Loss: 0.7449\n",
      "Epoch [3/50], Step [3/668], Val Loss: 0.7447\n",
      "Epoch [4/50], Step [4/668], Val Loss: 0.7446\n",
      "Epoch [5/50], Step [5/668], Val Loss: 0.7444\n",
      "Epoch [6/50], Step [6/668], Val Loss: 0.7442\n",
      "Epoch [7/50], Step [7/668], Val Loss: 0.7441\n",
      "Epoch [8/50], Step [8/668], Val Loss: 0.7439\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 50\n",
    "log_period = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        # todo change datatypes in dataset not in dataloader, use proper datatypes, output should be segmentation\n",
    "        inputs = batch['image'].to(device)#.float()\n",
    "        labels = batch['label'].to(device)#.float()\n",
    "        #img_A = img_A.to(device)\n",
    "        #img_B = img_B.to(device)\n",
    "\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss.item()\n",
    "        if i % log_period == log_period-1:  # Log every log_period batches\n",
    "\n",
    "        \n",
    "            # log training loss\n",
    "            writer.add_scalar('Loss/train', running_train_loss / log_period, epoch * len(train_loader) + i)\n",
    "            running_train_loss = 0.0\n",
    "\n",
    "            # Log reconstructed training images\n",
    "            img_grid = vutils.make_grid(outputs)\n",
    "            writer.add_image('reconstructed_training_images', img_grid, global_step=epoch * len(train_loader) + i)\n",
    "\n",
    "\n",
    "            # calculate validation loss\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    inputs = batch['image'].to(device)\n",
    "                    labels = batch['label'].to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "        \n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            # log validation loss\n",
    "            writer.add_scalar('Loss/val', val_loss, epoch * len(train_loader) + i)\n",
    "\n",
    "\n",
    "            # Log reconstructed validation images\n",
    "            img_grid = vutils.make_grid(outputs)\n",
    "            writer.add_image('reconstructed_validation_images', img_grid, global_step=epoch * len(train_loader) + i)\n",
    "\n",
    "            \n",
    "            print(f'Epoch [{epoch+1 + i}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Val Loss: {val_loss:.4f}')\n",
    "            \n",
    "            model.train()\n",
    "\n",
    "            \n",
    "            # ploting images like this until it works with tensorboard\n",
    "            #plt.figure()\n",
    "            #show_datapair(lables[0].cpu().detach().numpy(), outputs[0].cpu().detach().numpy())\n",
    "            #plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Validation step can be added here similarly and log validation loss\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
